{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "whisper_model = model\n",
    "\n",
    "\n",
    "def transcribe_audio_file(file_path, model = whisper_model):\n",
    "    # Transcribe the audio file\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "text1 = transcribe_audio_file(\"Jack Dorsey_1_17.mp3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 2016's challenge was re-accelerating our consumer usage.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "MODEL= f'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "tokenizer= AutoTokenizer.from_pretrained(MODEL)\n",
    "model= AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# Load the model\n",
    "model_ = whisper.load_model(\"base\")\n",
    "\n",
    "whisper_model = model_\n",
    "\n",
    "\n",
    "def sentiment(file_path):\n",
    "    def transcribe_audio_file(file_path, w_model = whisper_model):\n",
    "\n",
    "        sound = AudioSegment.from_file(file_path)\n",
    "        sound.export(\"./audio_mp3.mp3\", format=\"mp3\")\n",
    "        path_= 'audio_mp3.mp3'\n",
    "        # Transcribe the audio file\n",
    "        result = w_model.transcribe(path_)\n",
    "        return result[\"text\"]\n",
    "\n",
    "\n",
    "    text1 = transcribe_audio_file(file_path)\n",
    "\n",
    "    def polarity_score(example):\n",
    "        encoded_text= tokenizer(example, return_tensors='pt')\n",
    "        output=model(**encoded_text)\n",
    "        scores=output[0][0].detach().numpy()\n",
    "        scores=softmax(scores)\n",
    "        scores_dict={\n",
    "            'negative': scores[0],\n",
    "            'neutral': scores[1],\n",
    "            'positive': scores[2]\n",
    "        }\n",
    "        return scores_dict\n",
    "\n",
    "    scores = polarity_score(text1)\n",
    "\n",
    "    max_key = max(scores, key=scores.get)\n",
    "\n",
    "\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import random\n",
    "#PATH PROCESS\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "#IMAGE PROCESS\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg\n",
    "#MUSIC PROCESS\n",
    "import pydub\n",
    "from scipy.io.wavfile import read, write\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "#SCALER & TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#ACCURACY CONTROL\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#OPTIMIZER\n",
    "from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n",
    "#MODEL LAYERS\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n",
    "                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\n",
    "LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape,\\\n",
    "Conv2DTranspose, LeakyReLU, Conv1D, AveragePooling1D, MaxPooling1D\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.applications import VGG16,VGG19,inception_v3\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "#SKLEARN CLASSIFIER\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "#IGNORING WARNINGS\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data):\n",
    "    noise_value = 0.015 * np.random.uniform() * np.amax(data)\n",
    "    data = data + noise_value * np.random.normal(size=data.shape[0])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_process(data,rate=0.8):\n",
    "\n",
    "    return librosa.effects.time_stretch(data,rate= rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_process(data):\n",
    "    shift_range = int(np.random.uniform(low=-5,high=5) * 1000)\n",
    "\n",
    "    return np.roll(data,shift_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_process(data,sampling_rate,pitch_factor=0.7):\n",
    "\n",
    "    return librosa.effects.pitch_shift(data,sr= sampling_rate,n_steps= pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_process(data, sample_rate):\n",
    "\n",
    "    output_result = np.array([])\n",
    "    mean_zero = np.mean(librosa.feature.zero_crossing_rate(y=data).T,axis=0)\n",
    "    output_result = np.hstack((output_result,mean_zero))\n",
    "\n",
    "    stft_out = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft_out,sr=sample_rate).T,axis=0)\n",
    "    output_result = np.hstack((output_result,chroma_stft))\n",
    "\n",
    "    mfcc_out = np.mean(librosa.feature.mfcc(y=data,sr=sample_rate).T,axis=0)\n",
    "    output_result = np.hstack((output_result,mfcc_out))\n",
    "\n",
    "    root_mean_out = np.mean(librosa.feature.rms(y=data).T,axis=0)\n",
    "    output_result = np.hstack((output_result,root_mean_out))\n",
    "\n",
    "    mel_spectogram = np.mean(librosa.feature.melspectrogram(y=data,sr=sample_rate).T,axis=0)\n",
    "    output_result = np.hstack((output_result,mel_spectogram))\n",
    "\n",
    "    return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_process(path):\n",
    "\n",
    "    data,sample_rate = librosa.load(path,duration=2.5,offset=0.6)\n",
    "\n",
    "    output_1 = extract_process(data, sample_rate)\n",
    "    result = np.array(output_1)\n",
    "\n",
    "    noise_out = add_noise(data)\n",
    "    output_2 = extract_process(noise_out, sample_rate)\n",
    "    result = np.vstack((result,output_2))\n",
    "\n",
    "    new_out = stretch_process(data)\n",
    "    strectch_pitch = pitch_process(new_out, sample_rate)\n",
    "    output_3 = extract_process(strectch_pitch, sample_rate)\n",
    "    result = np.vstack((result,output_3))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='./audio_wav.wav'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "sound = AudioSegment.from_mp3(\"Jack Dorsey_1_17.mp3\")\n",
    "sound.export(\"./audio_wav.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/content/audio_wav.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files\\scaler_data', 'rb') as file:\n",
    "    scaler_data=pickle.load(file)\n",
    "\n",
    "with open(\"files\\encoder_label.pkl\", 'rb') as file:\n",
    "    encoder_label = pickle.load(file)\n",
    "\n",
    "Model = tf.keras.models.load_model('files\\Conv1D_Model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_sentiment(path):\n",
    "\n",
    "    sound = AudioSegment.from_file(path)\n",
    "    sound.export(\"./audio_wav.wav\", format=\"wav\")\n",
    "\n",
    "    path_= './audio_wav.wav'\n",
    "    x_Train=[]\n",
    "\n",
    "    features = export_process(path_)\n",
    "\n",
    "    for element in features:\n",
    "        x_Train.append(element)\n",
    "\n",
    "    new_predict_list= x_Train\n",
    "\n",
    "    New_Predict_Feat = pd.DataFrame(new_predict_list)\n",
    "\n",
    "    New_Predict_Feat = scaler_data.fit_transform(New_Predict_Feat)\n",
    "    New_Predict_Feat = np.expand_dims(New_Predict_Feat,axis=2)\n",
    "\n",
    "\n",
    "    prediction_nonseen = Model.predict(New_Predict_Feat)\n",
    "    arg_prediction_nonseen = prediction_nonseen.argmax(axis=-1)\n",
    "    y_prediction_nonseen = encoder_label.inverse_transform(prediction_nonseen)\n",
    "\n",
    "    most_scored_index = np.argmax(arg_prediction_nonseen)\n",
    "\n",
    "    # Get the corresponding class from y_prediction_nonseen\n",
    "    most_scored_class = y_prediction_nonseen[most_scored_index]\n",
    "\n",
    " \n",
    "\n",
    "    emotion_categories = {\n",
    "    'neutral': ['OAF_neutral', 'YAF_neutral', 'OAF_Pleasant_surprise', 'YAF_pleasant_surprised'],\n",
    "    'positive': ['YAF_happy', 'OAF_happy'],\n",
    "    'negative': ['YAF_fear', 'OAF_angry', 'OAF_Fear', 'OAF_disgust', 'YAF_angry', 'OAF_Sad', 'YAF_disgust', 'YAF_sad']\n",
    "    }\n",
    "\n",
    "    def find_category(class_name):\n",
    "        for category, classes in emotion_categories.items():\n",
    "            if class_name in classes:\n",
    "                return category\n",
    "        return None\n",
    "\n",
    "    # Example usage\n",
    "    class_name = most_scored_class[0] # Replace with the class you want to check\n",
    "    category = find_category(class_name)\n",
    "\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_sentiment(\"audios\\Jack Dorsey_6_5.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
